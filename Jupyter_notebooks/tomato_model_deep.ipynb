{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>star_power</th>\n",
       "      <th>first_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>36703349.28</td>\n",
       "      <td>41.109264</td>\n",
       "      <td>1972</td>\n",
       "      <td>1.499126e+09</td>\n",
       "      <td>175</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6024</td>\n",
       "      <td>1</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>43134278.00</td>\n",
       "      <td>51.645403</td>\n",
       "      <td>1994</td>\n",
       "      <td>4.889955e+07</td>\n",
       "      <td>142</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8358</td>\n",
       "      <td>1</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>96693277.31</td>\n",
       "      <td>63.869599</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.547917e+08</td>\n",
       "      <td>139</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9678</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>38930103.81</td>\n",
       "      <td>41.725123</td>\n",
       "      <td>1993</td>\n",
       "      <td>5.686725e+08</td>\n",
       "      <td>195</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4436</td>\n",
       "      <td>1</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>14258364.31</td>\n",
       "      <td>35.529554</td>\n",
       "      <td>1975</td>\n",
       "      <td>5.179649e+08</td>\n",
       "      <td>133</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3001</td>\n",
       "      <td>1</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1                            title       budget  popularity  \\\n",
       "0        0                    The Godfather  36703349.28   41.109264   \n",
       "1        1         The Shawshank Redemption  43134278.00   51.645403   \n",
       "2        2                       Fight Club  96693277.31   63.869599   \n",
       "3        3                 Schindler's List  38930103.81   41.725123   \n",
       "4        4  One Flew Over the Cuckoo's Nest  14258364.31   35.529554   \n",
       "\n",
       "   release_date       revenue  runtime  vote_average  vote_count  star_power  \\\n",
       "0          1972  1.499126e+09      175           8.5        6024           1   \n",
       "1          1994  4.889955e+07      142           8.5        8358           1   \n",
       "2          1999  1.547917e+08      139           8.3        9678           1   \n",
       "3          1993  5.686725e+08      195           8.3        4436           1   \n",
       "4          1975  5.179649e+08      133           8.3        3001           1   \n",
       "\n",
       "  first_genre  \n",
       "0       Drama  \n",
       "1       Drama  \n",
       "2      Comedy  \n",
       "3       Drama  \n",
       "4    Classics  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# File to Load (Remember to Change These)\n",
    "\n",
    "\n",
    "tomato_model_1 = \"../Resources/movie_metadata_adjusted_revenue_starpower.csv\"\n",
    "# Read the Data\n",
    "mv_df = pd.read_csv(tomato_model_1)\n",
    "from scipy import stats\n",
    "mv_df2 = mv_df[(np.abs(stats.zscore(mv_df['revenue'])) < 3)]\n",
    "mv_df3 = mv_df2[(np.abs(stats.zscore(mv_df2['budget'])) < 3)]\n",
    "tomato_df = mv_df3.dropna()\n",
    "tomato_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1063, 2) (1063, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = tomato_df[[\"star_power\", \"budget\"]]\n",
    "X_2 = tomato_df[[\"popularity\", \"vote_average\", \"vote_count\"]]\n",
    "y = tomato_df[\"revenue\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "#y_scaler = MinMaxScaler().fit(y_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "#y_train_scaled = y_scaler.transform(y_train)\n",
    "#y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jasonpe\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=15, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(units=15, activation='relu', input_dim=3))\n",
    "model2.add(Dense(units=15, activation='relu'))\n",
    "model2.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='msle',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#reduce_mean no\n",
    "#categorical_hinge yes\n",
    "#\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='msle',\n",
    "              metrics=['accuracy'])\n",
    "#\n",
    "#adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                45        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 332\n",
      "Trainable params: 332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jasonpe\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 797 samples\n",
      "Epoch 1/60\n",
      "797/797 - 1s - loss: 357.8410 - acc: 0.3275\n",
      "Epoch 2/60\n",
      "797/797 - 0s - loss: 357.8327 - acc: 0.7629\n",
      "Epoch 3/60\n",
      "797/797 - 0s - loss: 357.8314 - acc: 0.6449\n",
      "Epoch 4/60\n",
      "797/797 - 0s - loss: 357.8311 - acc: 0.6010\n",
      "Epoch 5/60\n",
      "797/797 - 0s - loss: 357.8310 - acc: 0.6336\n",
      "Epoch 6/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6537\n",
      "Epoch 7/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6637\n",
      "Epoch 8/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6688\n",
      "Epoch 9/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6575\n",
      "Epoch 10/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6763\n",
      "Epoch 11/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6437\n",
      "Epoch 12/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6173\n",
      "Epoch 13/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6198\n",
      "Epoch 14/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.6386\n",
      "Epoch 15/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.5972\n",
      "Epoch 16/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5558\n",
      "Epoch 17/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5872\n",
      "Epoch 18/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5496\n",
      "Epoch 19/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5019\n",
      "Epoch 20/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5558\n",
      "Epoch 21/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5345\n",
      "Epoch 22/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5320\n",
      "Epoch 23/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5270\n",
      "Epoch 24/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5696\n",
      "Epoch 25/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5307\n",
      "Epoch 26/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5496\n",
      "Epoch 27/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5471\n",
      "Epoch 28/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5169\n",
      "Epoch 29/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5282\n",
      "Epoch 30/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5433\n",
      "Epoch 31/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5307\n",
      "Epoch 32/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5320\n",
      "Epoch 33/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5684\n",
      "Epoch 34/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5282\n",
      "Epoch 35/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5395\n",
      "Epoch 36/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4718\n",
      "Epoch 37/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5646\n",
      "Epoch 38/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5220\n",
      "Epoch 39/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5157\n",
      "Epoch 40/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5496\n",
      "Epoch 41/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5056\n",
      "Epoch 42/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5684\n",
      "Epoch 43/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5383\n",
      "Epoch 44/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4580\n",
      "Epoch 45/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5345\n",
      "Epoch 46/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4969\n",
      "Epoch 47/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5759\n",
      "Epoch 48/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5483\n",
      "Epoch 49/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5747\n",
      "Epoch 50/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4755\n",
      "Epoch 51/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5772\n",
      "Epoch 52/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5696\n",
      "Epoch 53/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5307\n",
      "Epoch 54/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5107\n",
      "Epoch 55/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5609\n",
      "Epoch 56/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5621\n",
      "Epoch 57/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4969\n",
      "Epoch 58/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5207\n",
      "Epoch 59/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5521\n",
      "Epoch 60/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c1c53860f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 - 0s - loss: 355.5081 - acc: 0.5902\n",
      "Normal Neural Network - Loss: 355.50811216884983, Accuracy: 0.5902255773544312\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "print(f\"Predicted classes: {encoded_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = train_test_split(\n",
    "    X_2, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler2 = MinMaxScaler().fit(X_train2)\n",
    "X_train_scaled2 = X_scaler2.transform(X_train2)\n",
    "X_test_scaled2 = X_scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 797 samples\n",
      "Epoch 1/60\n",
      "797/797 - 0s - loss: 357.8349 - acc: 0.7917\n",
      "Epoch 2/60\n",
      "797/797 - 0s - loss: 357.8313 - acc: 0.2246\n",
      "Epoch 3/60\n",
      "797/797 - 0s - loss: 357.8311 - acc: 0.4705\n",
      "Epoch 4/60\n",
      "797/797 - 0s - loss: 357.8310 - acc: 0.4141\n",
      "Epoch 5/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.4090\n",
      "Epoch 6/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.4153\n",
      "Epoch 7/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.4341\n",
      "Epoch 8/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.4078\n",
      "Epoch 9/60\n",
      "797/797 - 0s - loss: 357.8309 - acc: 0.4944\n",
      "Epoch 10/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5270\n",
      "Epoch 11/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5395\n",
      "Epoch 12/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5496\n",
      "Epoch 13/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4467\n",
      "Epoch 14/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5358\n",
      "Epoch 15/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4693\n",
      "Epoch 16/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4768\n",
      "Epoch 17/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5232\n",
      "Epoch 18/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4730\n",
      "Epoch 19/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4642\n",
      "Epoch 20/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4956\n",
      "Epoch 21/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4642\n",
      "Epoch 22/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5220\n",
      "Epoch 23/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4454\n",
      "Epoch 24/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4718\n",
      "Epoch 25/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4718\n",
      "Epoch 26/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4743\n",
      "Epoch 27/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4718\n",
      "Epoch 28/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4580\n",
      "Epoch 29/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4818\n",
      "Epoch 30/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4693\n",
      "Epoch 31/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4893\n",
      "Epoch 32/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4605\n",
      "Epoch 33/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4806\n",
      "Epoch 34/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4806\n",
      "Epoch 35/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4906\n",
      "Epoch 36/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4442\n",
      "Epoch 37/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5220\n",
      "Epoch 38/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4630\n",
      "Epoch 39/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4354\n",
      "Epoch 40/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5332\n",
      "Epoch 41/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4843\n",
      "Epoch 42/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5056\n",
      "Epoch 43/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4755\n",
      "Epoch 44/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5345\n",
      "Epoch 45/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5044\n",
      "Epoch 46/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4793\n",
      "Epoch 47/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4918\n",
      "Epoch 48/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5006\n",
      "Epoch 49/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4969\n",
      "Epoch 50/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5332\n",
      "Epoch 51/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4856\n",
      "Epoch 52/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5257\n",
      "Epoch 53/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4969\n",
      "Epoch 54/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5282\n",
      "Epoch 55/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4956\n",
      "Epoch 56/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5082\n",
      "Epoch 57/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4956\n",
      "Epoch 58/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5408\n",
      "Epoch 59/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.4843\n",
      "Epoch 60/60\n",
      "797/797 - 0s - loss: 357.8308 - acc: 0.5107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c1d1d99da0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(\n",
    "    X_train_scaled2,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 - 0s - loss: 355.5081 - acc: 0.5977\n",
      "Normal Neural Network - Loss: 355.50811216884983, Accuracy: 0.5902255773544312\n"
     ]
    }
   ],
   "source": [
    "model_loss2, model_accuracy2 = model2.evaluate(\n",
    "    X_test_scaled2, y_test, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mape\n",
    "1439/1439 - 0s - loss: 99.9999 - acc: 0.0674\n",
    "Normal Neural Network - Loss: 99.99991681362043, Accuracy: 0.06740792095661163\n",
    "\n",
    "#mae\n",
    "1439/1439 - 0s - loss: 91092404.9590 - acc: 0.0028\n",
    "Normal Neural Network - Loss: 91092404.9589993, Accuracy: 0.002779708243906498\n",
    "\n",
    "#logcosh\n",
    "1439/1439 - 0s - loss: 91092404.4253 - acc: 1.0000\n",
    "Normal Neural Network - Loss: 91092404.42529534, Accuracy: 1.0\n",
    "\n",
    "#categorical_hinge\n",
    "1439/1439 - 0s - loss: 0.0000e+00 - acc: 0.0000e+00\n",
    "Normal Neural Network - Loss: 0.0, Accuracy: 0.0\n",
    "\n",
    "#msle\n",
    "1439/1439 - 0s - loss: 272.5723 - acc: 0.9840\n",
    "Normal Neural Network - Loss: 272.5723301805996, Accuracy: 0.9840166568756104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
